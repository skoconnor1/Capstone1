{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Logistic Regression and Random Forest Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from datetime import datetime\n",
    "from scipy.stats import stats\n",
    "from scipy.stats import norm\n",
    "from statsmodels.stats.weightstats import ztest\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function BufferedReader.close>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infile = open('../PickledFiles/RFandLR_preds', 'rb')\n",
    "predsRFandLR = pickle.load(infile)\n",
    "infile.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob_of_homewin_RF</th>\n",
       "      <th>pred_RF</th>\n",
       "      <th>game_result</th>\n",
       "      <th>prob_of_homewin_LR</th>\n",
       "      <th>pred_LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21867</th>\n",
       "      <td>0.550</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.536126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21868</th>\n",
       "      <td>0.518</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.423835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21869</th>\n",
       "      <td>0.721</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.689292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21870</th>\n",
       "      <td>0.461</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.430619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21871</th>\n",
       "      <td>0.590</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.487055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prob_of_homewin_RF  pred_RF  game_result  prob_of_homewin_LR  pred_LR\n",
       "21867               0.550        1            1            0.536126        1\n",
       "21868               0.518        1            1            0.423835        0\n",
       "21869               0.721        1            0            0.689292        1\n",
       "21870               0.461        0            0            0.430619        0\n",
       "21871               0.590        1            1            0.487055        0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsRFandLR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest = predsRFandLR['game_result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[479, 669],\n",
       "       [332, 951]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RF confusion matrix\n",
    "confusion_matrix(ytest, predsRFandLR.pred_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[677, 471],\n",
       "       [538, 745]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RF confusion matrix\n",
    "confusion_matrix(ytest, predsRFandLR.pred_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate avg of Logistic Reg and Random Forests predicted probabilities \n",
    "#will choose result if which ever model had higher confidence in prediction \n",
    "predsRFandLR['AvgProb'] = (predsRFandLR['prob_of_homewin_RF'] + predsRFandLR['prob_of_homewin_LR'])/2\n",
    "predsRFandLR['AvgPred'] = np.where(predsRFandLR['AvgProb']>.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test Classification Report:]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.50      0.53      1148\n",
      "           1       0.60      0.66      0.63      1283\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      2431\n",
      "   macro avg       0.58      0.58      0.58      2431\n",
      "weighted avg       0.58      0.59      0.58      2431\n",
      "\n",
      "Test Accuracy:  0.5857671740024681\n",
      "AUC:  0.6118743906512665\n"
     ]
    }
   ],
   "source": [
    "print(\"[Test Classification Report:]\")\n",
    "print(classification_report(ytest, predsRFandLR['AvgPred']))\n",
    "print('Test Accuracy: ',accuracy_score(predsRFandLR['AvgPred'], ytest))\n",
    "yprobs = predsRFandLR['AvgProb']\n",
    "fpr, tpr, threshold = roc_curve(ytest,  yprobs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC: ', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test Classification Report:]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.50      0.55       896\n",
      "           1       0.62      0.70      0.66      1021\n",
      "\n",
      "   micro avg       0.61      0.61      0.61      1917\n",
      "   macro avg       0.61      0.60      0.60      1917\n",
      "weighted avg       0.61      0.61      0.61      1917\n",
      "\n",
      "Test Accuracy:  0.6098069900886802\n"
     ]
    }
   ],
   "source": [
    "#see accuracy on ones where both models make same prediction of which team wins\n",
    "match = predsRFandLR[predsRFandLR.pred_RF == predsRFandLR.pred_LR]\n",
    "print(\"[Test Classification Report:]\")\n",
    "print(classification_report(match.game_result, match.pred_RF))\n",
    "print('Test Accuracy: ',accuracy_score(match.pred_RF, match.game_result))\n",
    "ytest = match.game_re\n",
    "fpr, tpr, threshold = roc_curve(ytest,  yprobs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC: ', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1917, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob_of_homewin_RF</th>\n",
       "      <th>pred_RF</th>\n",
       "      <th>game_result</th>\n",
       "      <th>prob_of_homewin_LR</th>\n",
       "      <th>pred_LR</th>\n",
       "      <th>AvgProb</th>\n",
       "      <th>AvgPred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21867</th>\n",
       "      <td>0.550</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.536126</td>\n",
       "      <td>1</td>\n",
       "      <td>0.543063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21869</th>\n",
       "      <td>0.721</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.689292</td>\n",
       "      <td>1</td>\n",
       "      <td>0.705146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21870</th>\n",
       "      <td>0.461</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.430619</td>\n",
       "      <td>0</td>\n",
       "      <td>0.445810</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21872</th>\n",
       "      <td>0.484</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.421855</td>\n",
       "      <td>0</td>\n",
       "      <td>0.452928</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21874</th>\n",
       "      <td>0.669</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.586793</td>\n",
       "      <td>1</td>\n",
       "      <td>0.627896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prob_of_homewin_RF  pred_RF  game_result  prob_of_homewin_LR  pred_LR  \\\n",
       "21867               0.550        1            1            0.536126        1   \n",
       "21869               0.721        1            0            0.689292        1   \n",
       "21870               0.461        0            0            0.430619        0   \n",
       "21872               0.484        0            0            0.421855        0   \n",
       "21874               0.669        1            0            0.586793        1   \n",
       "\n",
       "        AvgProb  AvgPred  \n",
       "21867  0.543063        1  \n",
       "21869  0.705146        1  \n",
       "21870  0.445810        0  \n",
       "21872  0.452928        0  \n",
       "21874  0.627896        1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran. For. Log Loss:  0.6768342560697054\n",
      "Log Reg Log Loss:  0.6744207602469292\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "print('Ran. For. Log Loss: ', log_loss(predsRFandLR.game_result, predsRFandLR.prob_of_homewin_RF, eps=1e-15))\n",
    "print('Log Reg Log Loss: ',log_loss(predsRFandLR.game_result, predsRFandLR.prob_of_homewin_LR, eps=1e-15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
